---
title: "5 -- Hypothesis testing"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The $z$-test

The $z$-test attempts to accept or reject a hypothesis about the *population average* by means of a sufficiently large sample.

### The right-tailed $z$-test

It is generally assumed that superheroes save an average of $\mu = 3.3$ people a day. Researchers want to check this and perform a random check on 30 superheroes. In this sample, the average is $\overline{x} = 3.483$. So we can suspect that superheroes on average perform *more* rescues.

The standard deviation in the population is assumed to be known and is $\sigma = 0.55$.

The hypothesis test runs as follows:

1. Formulate the hypotheses:
    - $H_0: \mu = 3.3$
    - $H_1: \mu > 3.3$
2. Choose a significance level, e.g. $\alpha = 0.05$.

    ```{r}
    # We have a sample with
    n <- 30 # sample size
    sm <- 3.483 # sample average
    s <- 0.55 # standard deviation (assumed known)
    a <- 0.05 # significance level (chosen by the researcher)
    m0 <- 3.3 # hypothetical population mean (H0)
    ```

3. Determine the value of the test statistic, in this case $\overline{x} = 3.483$.
4. Determine the $p$-value and reject $H_0$ if $p < \alpha$.

    ```{r}
    p <- 1 - pnorm (sm, m0, s/sqrt(n))
    p
    if(p < a) {
      print ("Reject H0")
    } else {
      print ("Do not reject H0")
    }
    ```
    
    An alternative calculation is to determine the *critical region*, i.e. the area within which $H_0$ may be rejected. The boundary of that area is called the critical (boundary) value $b$. On the left you can't reject $H_0$ (acceptance area), on the right $H_0$ is rejected (critical area). The size of the acceptance area is $1 - \alpha$, the size of the critical area is $\alpha$.

    ```{r}
    b <- m0 + qnorm(1-a) * s / sqrt(n)
    b
    # If the sample average found is below b, you cannot reject H0.
    if (sm < b) {
      print ("Do not reject H0")
    } else {
      print ("Reject H0")
    }
    ```
    
If we assume $H_0$ to be true, then the probability of selecting a sample from the population with the obtained sample average is very small. With the chosen level of significance, we can therefore reject the null hypothesis.

Note that both methods, using the $p$-value and using the critical (boundary) value, are equivalent and *always* give identical results!

Below is a plot of this case.

```{r}
# plot boundaries (x-values)
x <- seq(m0-4*s/sqrt(n), m0+4*s/sqrt(n), length=200)
# y values (follow the Gauss curve)
dist <- dnorm(x, m0, s/sqrt(n))
plot (x, dist, type = 'l', xlab = '', ylab = '')

# display the found sample mean using a red vertical line
abline(v=sm, col='red')
text(sm, 2, sm)

# plotting the acceptance area
i <- x <= b                   # values of x left of b
polygon(                      # plot these values on the graph
  c(x[i], b, b),
  c(dist[i], dnorm(b, m0, s/sqrt(n)), 0),
  col = 'lightgreen')
text(b,.5,signif(b, digits=4)) # show critical value

text(m0, 0.1, m0)             # hypothetical population mean
abline(v=m0)                  # draw a vertical line

text(m0, 1.5, 'acceptance range (H0)')
```

### The left tailed $z$-test

Suppose the result of the sample was $\overline{x} = 3.117$. Then we have reason to believe that the population average is *smaller* than 3.3. This we can verify with a left-tailed $z$-test.

1. Formulate the hypotheses:  
    - $H_0: \mu = 3.3$  
    - $H_1: \mu < 3.3$  
2. Choose a significance level, e.g. $\alpha = 0.05$.

    ```{r}
    n <- 30 # sample size
    sm <- 3.117 # sample average
    s <- 0.55 # standard deviation (assumed known)
    a <- 0.05 # significance level (chosen by the researcher)
    m0 <- 3.3 # hypothetical population mean (H0)
    ```

3. Determine the value of the test statistic, in this case $\overline{x} = 3.117$.
4. Determine the $p$-value and reject $H_0$ if $p < \alpha$.

    ```{r}
    p <- pnorm(sm, m0, s/sqrt(n))  # Caution! No "1-pnorm(...)". Why?
    p
    if(p < a) {
      print ('Reject H0')
    } else {
      print ('Do not reject H0')
    }
    ```
    
    The critical value $b$ is now on the left of the average. On the right of $b$ you can't reject $H_0$ (acceptance area), on the left of $b$ you *can* reject (critical area).
    
    ```{r}
    b <- m0 - qnorm(1-a) * s / sqrt(n)
    b
    # If the sample average found is above b, you cannot reject H0.
    if (sm < b) {
      print ('Reject H0')
    } else {
      print ('Do not reject H0')
    }
    ```
    
So we conclude that if we assume $H_0$, the probability of selecting a sample from the population with the obtained sample average is very small. With the chosen level of significance, we can therefore reject the null hypothesis.

The plot of this case.

```{r}
# plot boundaries (x-values)
x <- seq(m0-4*s/sqrt(n), m0+4*s/sqrt(n), length=200)
# y values (follow the Gauss curve)
dist <- dnorm(x, m0, s/sqrt(n))
plot (x, dist, type = 'l', xlab = '', ylab = '')

# Display the found sample mean ahv red vertical line
abline(v=sm, col='red')
text(sm, 2, sm)

# The acceptance area for plotting
i <- x >= b # Values of x to the right of b
polygon( # Plot these values on the graph
  c(x[i], b),
  c(dist[i], 0),
  col = 'lightgreen')
text(b,.5,signif(b, digits=4)) # Show limit value

text(m0, 0.1, m0) # Hypothetical population mean
abline(v=m0) # Draw a vertical line there.

text(m0, 1.5, 'acceptance area (H0)')
```

### The two-tailed $z$-test

With the two-tailed (or two-sided) $z$-test we are not interested if the population average is bigger or smaller, but if it is in line (or not in line) with the original value (here 3.3).

1. Hypotheses:
    - $H_0: \mu = 3.3$
    - $H_1: \mu \ne 3.3$
2. Choose significance level, e.g. $\alpha = 0.05$

    ```{r}
    n <- 30      # steekproefgrootte
    sm <- 3.483  # steekproefgemiddelde
    s <- 0.55    # standaardafwijking (verondersteld gekend)
    a <- 0.05    # significantieniveau (gekozen door de onderzoeker)
    m0 <- 3.3    # hypothetisch populatiegemiddelde (H0)
    ```

3. Determine the value of the test statistic: $\overline{x} = 3.483$
4. Determine the $p$-value and reject $H_0$ if $p < \frac{\alpha}{2}$ (Remark! Divide by 2!).

    ```{r}
    p <- pnorm(sm, m0, s/sqrt(n))
    p
    if(p < a/2) {
      print("H0 verwerpen")
    } else {
      print("H0 niet verwerpen")
    }
    ```
    
    Now we will have *two* critical values: $b_1$ at the left of the sample average and $b_2$ at the right. The total size of the critical area is still $\alpha$.
    
    ```{r}
    b1 <- m0 - qnorm(1-a/2) * s / sqrt(n) # lower limit of acceptance area
    b2 <- m0 + qnorm(1-a/2) * s / sqrt(n) # upper limit of acceptance area
    c(b1, b2)
    
    # If the sample average found is between b1 and b2, you cannot reject H0.
    if (b1 < sm & sm < b2) {
      print ('Do not reject H0')
    } else {
      print ('reject H0')
    }
    ```

The plot of this situation looks like this:

```{r}
# plot boundaries (x-values)
x <- seq(m0-4*s/sqrt(n), m0+4*s/sqrt(n), length=200)
# y values (follow the Gauss curve)
dist <- dnorm(x, m0, s/sqrt(n))
plot (x, dist, type = 'l', xlab = '', ylab = '')

# The acceptance area for plotting
i <- b1 <= x & x <= b2 # Values of x between b1 and b2
db1 <- dnorm(b1, m0, s/sqrt(n)) # probability density at b1 and b2
db2 <- dnorm(b2, m0, s/sqrt(n))
polygon( # Plot these values on the graph
  c(b1, b1, x[i], b2, b2),
  c(0, db1, dist[i], db2, 0),
  col = 'lightgreen')
text(b1,.5,signif(b1, digits=4)) # Show limit value
text(b2,.5,signif(b2, digits=4)) # Show limit value

text(m0, 0.1, m0) # Hypothetical population mean
abline(v=m0) # Draw a vertical line there.

text(m0, 1.5, 'acceptance range (H0)')

# Display the found sample mean using a red vertical line
abline(v=sm, col='red')
text(sm, 2, sm)
```

If, therefore, we do not make an a priori statement as to whether the actual population average is either smaller or larger, then it would appear that the sample average obtained is sufficiently likely. We cannot rule out the possibility of a random sampling error. Or, in other words, we can *not* reject the null hypothesis here. 

## The $t$-test

If the assumptions made to apply the $z$-test do *not* apply (e.g. the sample size is too small and/or the population standard deviation ($\sigma$) is unknown, then the $t$-test can be an alternative. There are again three variants of this test: left, right and two tailed. We will only work out the case for the right-tailed test here.

### Right tailed $t$-test

Suppose that the researchers of the superheroes were unable to take a sufficiently large sample due to time pressure and made only $n = 20$ observations, with the same sample average $\overline{x} = 3.483$. The standard deviation in this sample turned out to be $s = 0.55$.

In these circumstances, with the same significance level of $\alpha = 0.05$, can we sustain the conclusion that superheroes save *more* than 3.3 people every day?

The assessment procedure then runs as follows:

1. Formulate the hypotheses:
    $H_0: \mu = 3.3$
    $H_1: \mu > 3.3$
2. Choose a significance level, e.g. $\alpha = 0.05$.

    ```{r}
    # We have a sample with
    n <- 20 # sample size
    sm <- 3.483 # average of the sample
    ss <- 0.55 # standard deviation of the sample
    a <- 0.05 # significance level (chosen by the researcher)
    m0 <- 3.3 # hypothetical population mean (H0)
    ```

3. Determine the value of the test statistic: $\overline{x} = 3.483$.
4. Determine the $p$-value and reject $H_0$ if $p < \alpha$. Note that the function `pt()` does not allow to give mean and standard deviation. So, we have to normalize the values ourselves. I.e. we have to calculate a $t$-score: $t=\frac{\overline{x}-\mu_0}{\frac{s}{\sqrt{n}}}$.

    ```{r}
    t = (sm - m0) / (s/sqrt(n))
    p = 1 - pt(t, df = n-1)
    p
    if(p < a) {
      print ('reject H0')
    } else {
      print ('Do not reject H0')
    }
    ```
    
    When calculating the critical value, we use the `qt()` function with $n - 1$ degrees of freedom.
    
    ```{r}
    b <- m0 + qt(1-a, df = n-1) * s / sqrt(n)
    b
    # If the sample average found is below b, you cannot reject H0.
    if (sm < b) {
      print ('Do not reject H0')
    } else {
      print ('reject H0')
    }
    ```
    
The plot for this situation:

```{r}
# plot boundaries (x-values)
x <- seq(m0-4*ss/sqrt(n), m0+4*ss/sqrt(n), length=200)
# y values (following the Gauss curve of the t distribution)
dist <- dt((x-m0)/(ss/sqrt(n)), df = n-1) * ss/sqrt(n)
plot (x, dist, type = 'l', xlab = '', ylab = '')

# The acceptance area for plotting
# Values of x left of b
i <- x < b                    
# value density function for b
db <- dt((b-m0)/(ss/sqrt(n)), df=n-1) * ss/sqrt(n)
#Plot these values on the graph
polygon(
  c(x[i], b, b),
  c(dist[i], db, 0),
  col = 'lightgreen')
text(m0, 0.02, 'Acceptance area (H0)')

# Draw a vertical line in the hypothetical population mean
text(m0, 0.01, m0)
abline(v=m0)

# Display the critical limit value
text(b+.025,.005,signif(b, digits=4))

# Display the found sample mean ahv red vertical line
abline(v=sm, col='red')
text(sm-.025, .04, sm, col = 'red')

```

In other words, even if we get similar results in our sample, we cannot make the same decision. Because our sample is too small, there is greater uncertainty as to whether the value of the sample average is extreme enough to reject the zero hypothesis.

### Use of the `t.test()` function

In R there is a function `t.test` that you can use to perform the test on a collection of observations.

```{r}
test_sample = c(                   # the sample
  3, 2, 3, 1, 10, 4, 2, 7, 3, 0,
  3, 1, 2, 3, 4, 0, 3, 8, 3, 7)
a = 0.05                           # significance level
m0 = 3.3                           # hypothetical population mean (H0)

t.test(test_sample, 
       alternative = "greater",    # right-tailed test
       mu = m0,                    # average hypothesis
       conf.level = 1 - a)         # confidence level
```

The conclusion here is that the sample average of 3.45 is not yet a reason to reject the null hypothesis because the $p$-value ($p = 0.4013 = 40.13\%$) is greater than the significance level $\alpha = 0.05=5\%$.

### The $t$-test for two *independent* samples

The $t$ test can also be used to compare two samples. First we show the case of *independent* samples taken separately.

The aim of a clinical trial is to determine whether a new drug reduces the reaction speed as a side effect (Lindquist, g.d.).
- 6 participants got a placebo (control group)
- 6 others were given the drug (treatment group)
Next, their reaction time to a stimulus was measured (in ms). We want to investigate whether there is a significant difference between the control group and treatment group.

Control group: 91, 87, 99, 77, 88, 91
treatment group: 101, 110, 103, 93, 99, 104

We must distinct following values:
- $\mu_1$ for the population average of the untreated population
- $\mu_2$ for the population average of the patients taking the medicine
- $\overline{x}$ for the sample average of the control group (placebo)
- $\overline{y}$ for the sample average of the treatment group (drug)

If the drug has an impact on the reaction speed, then the control group will be *faster* than the treatment group. I.e. the reaction *time* will be *smaller* ("less").

```{r}
control <-   c(91,87,99,77,88,91)
treatment <- c(101,110,103,93,99,104)
t.test(control, treatment, alternative="less")
```

The average response time of the control group (88.83) indeed appears to be significantly lower than that of the treatment group (101.67).

Note that in the call of `t.test()` the significance level (5%) and the assumed population average ($\mu_1 - \mu_2 = 0$) were not specified. They match the default values of `t.test()`.

### The $t$-test for *paired* samples

In this variant of the $t$-test, a measurement has been performed on each element of the sample, one time *before* and one time *after* an intervention. The aim is to check whether this intervention has had a significant effect on the measurement.

A study examined whether cars running on petrol with additives also have a lower consumption. Ten cars were first refuelled with either regular petrol or petrol with additives (determined by folding up a coin), after which consumption was measured (expressed in miles per gallon). The cars were then refilled with the other type of petrol and the consumption was measured again.

By means of a **paired** $t$-test, we check whether cars drive significantly more efficiently on petrol with additives.

```{r}
regular <- c(16,20,21,22,23,22,27,25,27,28)   # miles per gallon
additives <- c(19,22,24,24,25,25,26,26,28,32) # miles per gallon
t.test(additives, regular, alternative="greater", paired=TRUE)
```

The option 'paired=TRUE' indicates that this is a paired $t$-test.

The $p$-value, 0.0007749, is below the significance level of 0.05, so we can reject the null hypothesis. According to this sample, cars do indeed drive more efficiently on petrol with additives.

### Use of "group by" (`~`) in the `t.test` function

In the function `t.test` you can also use the group by operator (`~`). For example, in the dataset `mtcars` you can ask the question 'Are cars with a manual gearbox (am=1) more economical than those with automatic transmission (am=0)?

We look a the value "miles per gallon" (mpg). The more miles you can drive per gallon, the more economical the car can be called.

With `~ am` the data is divided in 2 test sets: those with am=0 (automatic) and those with am=1 (manual transmission)

```{r}
t.test(mpg ~ am, data = mtcars, alternative = 'less')
```

The $p$ value is very small, so even with a 99% signalling level you could reject the zero hypothesis.

**Remark**: If you look at the data set more closely, you will see that smaller, cheaper cars tend to have a manual gearbox while bigger, more expensive cars tend to have automatic transmission. Smaller cars can obviously drive more miles per gallon.